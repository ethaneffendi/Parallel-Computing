<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="" />
  <title>Ethan Effendi - Parallel Computing</title>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <link href="style.css" rel="stylesheet" type="text/css">
</head>
<body>
  <hr>

  <!--Threads and Processes in Python-->
  <h1 class="text">Threads and Processes in Python</h1>
  <p class="text">
    In Python, a running instance of a full application is called a process.
    One process can be broken up into many smaller tasks that work together to make the full app run smoothly.
    These smaller tasks are called threads.
    The operating system manages how and when threads and processes are executed.
  </p>
  <p class="text">
    Single-threading is the practice of having the multiple threads in one process run sequentially.
    Each thread waits for the one before it to finish before executing.
    If one thread takes a long time to execute, however, it becomes a bottleneck.
    The solution to this inefficiency is multithreading.
    Multithreading is the practice of allowing more than one thread to execute simultaneously.
    In particular, multiple threads are executed simultaneously using a technique called time slicing.
    The CPU switches between working on different threads so quickly that it seems as though the threads are running in parallel.
    Threads in the same process share the same resources (namely memory), so synchronization is necessary.
    Mechanisms exist for ensuring that no more than one concurrent thread can process and execute a particular portion of a program at once.
    Restricting execution of these special portions of code, called critical sections, to one thread at a time prevents data conflicts that might happen when two or more threads are reading and writing from the same shared memory.
    For working with threads and implementing multithreading, Python has a module called <code>threading</code>.
  </p>
  <p class="text">
    For true parallelism in Python, one must work with processes.
    Multiprocessing is the practice of distributing concurrent processes among multiple CPUs (usually the cores in a multicore processor) that work in parallel.
    In Python, working with processes and implementing multiprocessing can be done using the <code>multiprocessing</code> module. Downsides to multiprocessing exist, however.
    For example, concurrent processes do not share memory.
    They communicate with one another through interprocess communication methods provided by the operating system.
    Thus, communication among processes is not as efficient or quick as communication among threads.
    Also, a process is heavier than a thread.
    Context switching between different processes (pausing the current process to work on another) takes more time than context switching between different threads.
  </p>
  <img src="(1) Threads and Processes in Python/Threads and Processes.png" width=45%>
  <hr>

  <!--The threading Module-->
  <h1 class="text">The <code>threading</code> Module</h1>
  <p class="text">
    To create and customize thread objects using <code>threading</code>, one must follow several steps.
  </p>
  <ol class="text">
    <li>
      Define a subclass of <code>threading.Thread</code>.
    </li>
    <li>
      Override <code>__init__(self [,args])</code> in the subclass of <code>threading.Thread</code> for custom parameters that will be used to provide the thread with needed data.
    </li>
    <li>
      Override <code>run(self [,args])</code> to define what a thread should do when executed.
    </li>
    <li>
      Execute the thread by calling its <code>start()</code> function, which will in turn call <code>run()</code>.
    </li>
    <li>
      To make sure that Python waits for all threads that have been created and executed to finish before it moves to the sequentially next part of the program, call the <code>join()</code> function on each thread.
    </li>
  </ol>
  <script src="https://gist.github.com/ethaneffendi/f7e23ae9de8d76afaf149b36e921facd.js"></script>
  <p class="text">
    The code above makes a thread for each job that needs to be done.
    What if a thousand tasks need to be completed though?
    Wouldn't it be more efficient to just have five or so threads that split the work instead of making one thousand threads?
    The solution is using Python's <code>queue</code> module.
    Queues are a FIFO data structure that are useful for doing the same job on thousands of different inputs.
    Each thread's <code>run()</code> function will use a while true loop to pop an input out of the queue (try-except-else block) and process it using another function.
  </p>
  <hr>

  <!--The multiprocessing Module-->
  <h1 class="text">The <code>multiprocessing</code> Module</h1>
  <p class="text">
    Similar to working with threads in <code>threading</code>, one can make a process in <code>multiprocessing</code> by subclassing <code>multiprocessing.Process</code>, overriding the subclass's initializer, overriding the subclass's <code>run</code> function, and calling <code>start()</code> and <code>join()</code> in Python's main process.
    However, an alternative way of making processes exists. In Python's main process, one can instantiate <code>Process</code> with a <code>target</code> argument that is the function the process should run. The process receives the arguments of the function passed as an argument to the <code>target</code> parameter via a tuple passed to the <code>args</code> parameter of the constructor.
  </p>
  <script src="https://gist.github.com/ethaneffendi/45bb3474df2d4031346264933ada804f.js"></script>
  <p class="text">
    Python's <code>multiprocessing</code> module provides another solution for running processes in parallel. If the same function needs to be run on a collection of data, one should use the <code>multithreading.Pool</code> class.
    It takes a function and a collection. It runs the function on each member of the collectin as input and returns an output collection such that every element of the output corresponds by index to every element of the input.
  </p>
  <script src="https://gist.github.com/ethaneffendi/9186850b9b86677b123de3fa257dec05.js"></script>
  <hr>

  <!--A Very Brief Introduction to Patterns-->
  <h1 class="text">A Very Brief Introduction to Patterns</h1>
  <p class="text">
    Just as there are numerous data structures and algorithms to choose from when solving sorting or searching problems, there are many different patterns one can use for implementing parallelism in any program.
    Knowing which pattern fits which problem is key to being a master of parallelism. Thus, exploring different patterns and their uses will be the main focus from here on out.
  </p>
  <hr>

  <!--Map-->
  <h1 class="text">Map</h1>
  <p class="text">
    Map is one of many parallel patterns.
    It is the parallel equivalent of the kind of for loop in which each iteration of the loop body is independent of the others.
    What happens in the loop body of map's serial equivalent is called the elemental function in parallelism terms.
    A map takes in a collection as input.
    Each instance of the elemental function processes an entry from the input collection to produce an output collection of equal shape.
  </p>
  <img src="(5) Map/Parallel Map vs. For Loop With Independent Iterations.png" width=45%>
  <p class="text">
    Map is useful for applications like computing the Mandelbrot set, ray tracing, and Monte Carlo sampling.
    It can be implemented using <code>multiprocessing</code>'s <code>Pool</code> class.
  </p class="text">
  <h2 class="text">Mandelbrot Set</h2>
  <p class="text">
    The Mandelbrot set is a very special set in mathematics that is an icon of the study of fractals.
    Its fascinating history and various details are best explored in Robert Devaney's article: https://www.webpages.uidaho.edu/~stevel/565/literature/Unveiling%20the%20Mandelbrot%20Set.pdf.
    Computing what complex numbers are a part of the Mandelbrot set and then displaying the set graphically is incredibly slow when done using a sequential program.
    Luckily, the map is the right parallel pattern for speeding up working with the Mandelbrot set.
  </p>
  <p class="text">
    How does the Mandelbrot set work though? It is produced using iteration, the process of repeatedly applying a mathematical function.
    The function used to produce the Mandelbrot set is a quadratic polynomial \(x^2 + c\) when \(c\) is a constant. To iterate \(f(x)=x^2+c\), a seed, some starter \(x\) value called \(x_0\) is needed.
    \(x_0, x_1=(x_0)^2+c, x_2=(x_1)^2+c, ... , x_n = (x_{n-1})^2+c\).
  </p>
  <p class="text">
    Sometimes, orbits oscillate. For example, take the orbit of \(0\) under iteration of \(f(x)=x^2-1\).
    \(x_0 = 0, x_1 = (0)^-1=-1, x_2=(-1)^2-1=0, x_3=(0)^2-1=-1\).
    Other times, orbits, such as the orbit of \(0\) under iteration of \(f(x)=x^2\), remain fixed for all iterations.
    \(x_0, x_1=(0)^2=0, x_2=(0)^2=0, x_3=(0)^3=0\).
    Still, there are other orbits such as the orbit of \(0\) under iteration of \(f(x)=x^2+1\) that shoot to infinity.
    \(x_0=0, x_1=(0)^2+1=1, x_2=(1)^2+1=2, x_3=(2)^2+1=5, x_4=(5)^2+1=26, x_5=(26)^2+1=677, ...\).
  </p>
  <p class="text">
    The Mandelbrot set consists of all compex \(c\) values for which the corresponding orbit of \(0\) under \(x^2+c\) does not escape to infinity.
  </p>
  <p class="text">
    The algorithm for computing and then visualizing the Mandelbrot set can be summarized in five steps.
    Because these steps are performed on many \(c\) values, map may be applied to speed the job up.
  </p>
  <ol class="text">
    <li>Let \(c\) be a complex constant.</li>
    <li>Let \(x_0\) be the first complex iteration.</li>
    <li>Iterate once by letting \(x_n=x_{n-1}^2+c\).</li>
    <li>Repeat step 3 until one of the following occurs.</li>
    <ol>
      <li>The modulus of \(x_n\) exceeds some big number \(\epsilon\). This is the test for divergence. \(c\) is not a member of the Mandelbrot set (say that it should be colored white in the visualization on the complex plane of \(c\) values).</li>
      <li>The number of iterations exceeds a given value. This is the test for convergence. \(c\) is a part of the Mandelbrot set, so it should be colored black in the visualization.</li>
    </ol>
    <li>Draw the points.</li>
  </ol>
  <img src="(5) Map/Mandelbrot Set/Mandelbrot Set Visualization.png" width=30%>
  <p class="text">
    The code for computing and visualization the Mandelbrot set in sequence is shown below.
  </p>
  <script src="https://gist.github.com/ethaneffendi/16d21b67cf52fd07819f685077369666.js"></script>
  <p class="text">
    the code for computing the set in parallel using map and then visualizing it is shown below.
  </p>
  <script src="https://gist.github.com/ethaneffendi/ab95c58e1684c7576783887d5f1f815e.js"></script>
  <p class="text">
    The parallel code above takes on average around 0.53 seconds to compute the set.
    The serial code above takes on average around 1.77 seconds to compute the set.
    The program in parallel is a little more than three times faster than the program in serial.
    The device used was Apple's base model A2338 laptop.
  </p>
  <h2 class="text">Ray Tracing</h2>
  <p class="text">
    When computers need to take a 2D snapshot of a 3D space, computers use a technique called ray tracing.
    The computer has its eye at a point \(O(0,0,0)\).
    It will look through a frame some distance \(d\) in front.
    The frame has the dimensions \(V_w\) by \(V_h\).
    When \(V_w=V_h=d=1\), the camera has a \(53°\) field of vision.
    This frame is called the viewport.
  </p>
  <p class="text">
    The computer should cut the viewport into squares.
    Then, it should determine the color in each square and copy it to the corresponding pixel in an image.
    That image will be the computer's 2D snapshot of the 3D space.
  </p>
  <p class="text">
    To determine which square on the viewport corresponds to which pixel in the image to be produced, one should use the formulas \(V_x=C_x\cdot\frac{V_w}{C_w}\) and \(V_y=C_y\cdot\frac{V_h}{C_h}\) when \(C_x\) and \(C_y\) are coordinates of the pixel in question.
    \((V_x, V_y, V_z)\) is the corresponding point on the viewport when \(V_z=1\).
  </p>
  <p class="text">
    Next, the computer must determine what color of light comes through \((V_x, V_y, V_z)\).
    The computer does this by running a ray through \(O(0,0,0)\) and \((V_x, V_y, V_z)\) until the ray hits some object.
    The color of the object where the object is it becomes the color of \((V_x, V_y, V_z)\).
  </p>
  <p class="text">
    A ray passes through \(O\) and its direction is \((V-O)\) when \(V\) is the point on the viewport that the ray passes through.
    The equation of the ray is \(P=O+t(V-O)\) when \(t\) is a real number such that \(t\in(-\infty, \infty)\).
    By plugging in every value of \(t\) on \((-\infty, \infty)\), one gets every point \(P\) on the ray.
    For notational simplicity, direction \((V-O)\) may be written as \(\vec{D}\).
  </p>
  <p class="text">
    To begin experimenting, one needs objects in the 3D scene for rays to hit.
    Spheres are easy objects to begin working with.
    Spheres are sets of points that lie a fixed distance away from a fixed center \(C\).
    The distance from the center to any point on the sphere is the sphere's radius \(r\).
    \(r=distance(P,C)\).
    The distance between \(P\) and \(C\) is the length of the vector from \(P\) to \(C\).
    \(|P-C|=r\).
    The length of the vector is the square root of its dot product with itself: \(\sqrt{\left\langle P-C, P-C \right\rangle}\).
    Thus, \(r^2 = \left\langle P-C, P-C \right\rangle\).
  </p>
  <p class="text">
    Now, with \(P=O+t\vec{D}\) and \(r^2 = \left\langle P-C, P-C\right\rangle \), one may determine whether or not a ray and sphere intersect (and if so, where).
    By substitution, \(r^2 = \left\langle O+t\vec{D}-C, O+t\vec{D}-C\right\rangle \).
    Finding the values of \(t\) that satisfy \(r^2 = \left\langle O+t\vec{D}-C, O+t\vec{D}-C\right\rangle\) allow for substitution to the ray equation to find all points of intersection.
    Let \(\vec{CO}=O-C\) for notational simplicity.
    \(r^2 = \left\langle \vec{CO}, \vec{CO} \right\rangle + \left\langle t\vec{D}, \vec{CO} \right\rangle + \left\langle \vec{CO}, t\vec{D} \right\rangle + \left\langle t\vec{D}, t\vec{D} \right\rangle \).
    \(t^2 \left\langle \vec{D}, \vec{D} \right\rangle + t(2\left\langle \vec{CO}, \vec{D} \right\rangle) + \left\langle \vec{CO}, \vec{CO} \right\rangle -r^2 = 0\).
  </class>
  <p class="text">
    Now, let \(a = \left\langle \vec{D}, \vec{D} \right\rangle\), \(b = 2\left\langle \vec{CO}, \vec{D} \right\rangle\), and \( \left\langle \vec{CO}, \vec{CO} \right\rangle\ - r^2\) so that \(at^2 + bt + c = 0\).
    The quadratic equation can be solved for where a ray and sphere intersect. If they intersect twice (the ray goes through the sphere instead of skiffing as a tangent), the closer \(t\) should be chosen.
  </p>
  <p class="text">
    The product of code below is shown in this image:
  </p>
  <img src="(5) Map/Ray Tracing/Ray Traced Image.png" width=30%>
  <p class="text">
    A serial program for ray tracing is shown below.
  </p>
  <script src="https://gist.github.com/ethaneffendi/7beba9ee0d581450669929c5c5ba0481.js"></script>
  <p class="text">
    The program written with the implementation of map is shown below.
  </p>
  <script src="https://gist.github.com/ethaneffendi/c2419f75ed87d8082cd407ea7073ba3e.js"></script>
  <p class="text">
    The serial program took an average of about 18 seconds to run whereas the parallel program took an average of about 5 seconds to run.
    Thus, the parallel program is more than three times faster on the parameters provided.
    Tests were done using Apple's base model A2338 laptop.  
  </p>
  <hr>




</body>
</html>
